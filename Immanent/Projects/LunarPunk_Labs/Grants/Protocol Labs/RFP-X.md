# Semantic Networks for Practical Language Evolution

### [LunarPunk_Labs](lunapunklabs.org) - [University of the Third Horizon](h3uni.org)

1. **Research question**: How do we increase relevance on internet to aid the realisation of knowledge into understanding while effectively bridging the gap from research to implementation?  

2. **Research problem statement**: To keep up with the [worlds rising complexity](https://necsi.edu/complexity-rising-from-human-beings-to-human-civilization-a-complexity-profile) we'll need to improve deepen our human capacities for representation and interpretation by [augmenting our intellect](https://www.dougengelbart.org/pubs/augment-3906.html). 

3. **Proposed solution**: An ecosystem level partnership between Protocol Labs and Regen Ledger to bootstrap Semantic Impact Markets with 'adaptive capital' via a Tokenomics DAO. We propose systematically structured conversation graphs as a means of classifying parametric groupings into Friston blankets to enable semantically composable eco-credits as 'hypercerts'. Framing model metadata as functional information geometries that group such parameters provides epistemological transparency; a necessity for both governance and scientific research. We propose further transdiciplinary research and applied practice into the nuances of implementing the technology necessary for semantically composable impact markets.


# Related work 
## Problem Framing as Market Hypothesis
Before innovating on such financial technology, let's articulate some working assumptions about the market in order to progressively approximate some enabling constraints. Let's start with the major market participants and then examine the forces which move them.

#### Participants (Who)
> - Alpha investors; risk-on. Seeks return on investment. Quantifiers.
> - Beta investors; risk-off. Seeks wealth preservation. Qualifiers.

Our first assumption is that there are two broad sets of market participants that have different risk appetites. The first set of participants are alpha investors and the second set are beta investors. The former have a high risk appetite and the latter a low risk appetite; one set seeks to beat the market and the other desires to 'be' the market. 

Animating these actors, let's characterise our alpha investors as hedge funds and our beta investors as pension funds. Here we notice that the former is incentivised by carrots in the form of returns, while the latter does it's best to avoid the stick of regulation and corporate responsibility. Note that costs / risks / benefits moves both sets of participants at a fundamental level. Blue funds or impact markets mediate this by opening up new markets for both appetites.

#### Institutional Constraints (Why)
The next assumption about markets is that there are [two trillion dollars of stranded assets](https://carbontracker.org/reports/stranded-assets-danger-zone/) that are traded on Wall St. books. These assets take multiple forms but generally speaking they are below ground commodities like coal, oil and gas, which can't be extracted due to planetary boundary conditions. As these commodities have no intrinsic value their existence essentially depends on an irrational market; when it sobers up these assets will need to be 'struck from the books'.  

Both investor profiles are consequentially searching for new stores of value; a phenomena observable through the hedge fund embrace of qualitative indicators such as ESGs. As always, there is a deal of controversy about the efficacy of these specific values and though imperfect in themselves ESG's have sufficient traction to suffice as a general set of heuristics that help make intervention points more evident.

Regardless of the specific values, it's apparent that both of our investor profiles are caught in a dilemma of reconciling qualitative values with quantitive measures. Market participants have plenty of motivation to divest their capital but they lack profitable investment vehicles that can account for a given set of values in a quantifiable manner that meets the market. 

#### Economic Pathways (How)
Provisioning divestment options consequentially requires the opening of new markets and a set of market makers that hold a completely different mentality from what we know and have seen before. Instead of externalising costs, as entrepreneurs have done in the past, the demands upon the new breed of market makers will be to supply products that instead internalise and account for values. This is essentially a [two trillion dollar market opportunity](two trillion dollars of stranded assets](https://carbontracker.org/reports/stranded-assets-danger-zone/) for blue funds / impact capable of facilitating such a transformation; the question is what kind of products would such a marketplace either need or want? 

Examining economics in terms of nouns and verbs helps us to distinguish **capital** from **currencies**. Currencies (current-sees) are measures of value flow across time, whereas capital arises from integrating these flows. In that regard we see two forms of measure; the qualitative and quantitive.

From the quantitive perspective input measurements with the potential for aggregation might include GIS data, bio-acoustics, nutrient density or Brix values ect. These measures are useful at the data level but aggregating them becomes difficult due to a lack of interoperable and composable standards, which is also an issue for the qualitative accounting of heuristics like ESGs. The representation, organisation and translation of such values is a scientific and technical challenge that is only just becoming solvable. 

When it comes to these scientific and technological realms, Markov / Friston blankets can help in this matter by providing a means to bound unwieldy complexity into something more manageable. These serve as a base medium from which higher order systems can be assembled. Essentially, this means that we can now compose data streams into information classes to further build more structured and systematic relationships.

This probably satisfies our alpha investors who are seeking volatility and consequentially look towards more complex speculative instruments in the pursuit of their asymmetric returns. This is where the notion of 'adaptive capital' starts to become an interesting pathway. 

#### Adaptive capital (What)
Paradigms like natural capital accounting and payments for ecosystem services have tended towards controversy because much of life's intrinsic value is implicit in experience. The complex adaptive behaviour of natural systems is extremely hard to package into a product so we might more easily bootstrap new markets from legacy paradigms running on new infrastructure. From carbon, to co-benefits... to adaptive living capital. 

As far as instrument design goes, the representation of noun like products such as carbon is relatively easy. Moving beyond such basic designs we can augment these classic commodities with co-benefits, and beyond that again towards the real-time representation of ecological state. Such a future requires dynamic schemas.

For example, if the ESG heuristics (or SDGs ect) are considered to be our markets aspirational values, we still need to measure, account for and evaluate progress towards them. Such functionality is a necessary substrate to enable the representation of complex and adaptive capital. For such vehicles to arise would require the composition of at least several interoperable standards.

- Ground: Sensing Data (Monitoring, Reporting, Verification)
- Ideal: Evaluation criterea (e.g Environmental, Social, Governance)
- Instrumental: Blockchain accounting (Resource, Event, Agent) 
- Directive: Community culture (Agents, Languages, Perspectives)

To represent these standards in a composible way themselves, we can look back to markov blankets as a form of binding agent that allows for nesting at various levels of scale. The above represents a core feature set we might consider 'good' but not definite. Significantly, these blankets can give rise to a number of conceptual primitives around impact markets; namely conversation graphs which represent certifications or evaluation criterea, while they are also relevant as an API layer for loading arbitrary input schemas (from sensors or other interfaces).

- Purpose: Ledger Based Accounting
- Values: Impact evaluators
- Significance: Systematised Markov Blankets for Active Inferencing
- Facts: Impact certificates
- Resource: Sensing / sensors

This kind of architecture is general enough to be instantiated for any given application; be it simple commodities or a chain of complex systems. In this manner we can consider markov blankets to be a form of interface that enables arbitrary input data to be composed, accounted for, certified and evaluated. 

Looking back to our investor needs, we note that such a system can adapt to requirements across scales without disruption; from local monitoring, reporting and verification data to global market values like ESGs. Because there is an aggregation of live data feeds getting evaluated against an ideal state, there is also an investible delta for market participants to profit from. 

Accounting for a set of articulated values and then evaluating these against the free energy principal also makes the vehicle an unenclosable carrier; that which doesn't trend towards harmony fails as an investment vehicle, while that which does succeeds. Regenerative activity subsequently fits to financial return and speculative market activity consequentially funnels capital upstream to proletariats working on regenerative projects in the long term, while also allowing investors seeking to divest to earn delta in the short term to drive the process of transformation.

Beyond market conditions the semantic web is a particularly hard problem because it requires a confluence of factors to emerge across disciplines in precise synchrony. The key question is what timely innovations are needed to bridge the gap between research and implementation?

## State of art(s)

Over the years there has been a plethora of research on the semantic web and related topics but from the perspective of this author centres around is Doug Englebarts “[Augmenting Human Intellect](https://www.dougengelbart.org/content/view/138/)” and his many other innovations at Xerox Parc. Thankfully these ideas are once again gaining the attention they dearly deserve; with a fresh and funky twist even!

#### **Interface Design**
Assuming the affordances of Englebarts architectures, his associate Ted Nelson conceived of [Project Xanadu](https://en.wikipedia.org/wiki/Project_Xanadu) in the 60’s, becoming a pioneer in the fields of interaction design and representation. His body of foundational research around ‘the memeplex’ now seems to be sprouting into a fresh implementation cycle as evident in ‘second brain’ style products like Obsidian. This is fantastic progress in a space that’s once again beginning to move fast.
![](assets/HypercertsInterface.png)

#### **Data Security and Network Integrity**
When considering a vision of a free and open internet that serves humanity, the most fundamental first principle to consider is the software security model. This model dictates a set of design affordances through the principle of inheritance. With the growing shift in preferences from centralized to decentralized computing, we have inadvertently started to re-adopt a [“capabilities”](https://www.youtube.com/watch?v=qZ2LltOmD5A&t) oriented security model at the network level. This architecture can be seen manifesting in the form of cryptographic tokens that are stored on [distributed ledgers](https://www.regen.network/) and controlled through [wallet](https://www.pillar.fi/) addresses. The progress has been rapid from our shallow time frame but the field still has plenty of [scope for development](https://subconscious.network/) resting upon [dormant potentials](http://ceptr.org/). 

#### **Algorithmic 'intelligence'**
Between interfaces and distributed data storage lie algorithmic programmes; a primitive form of associative intelligence particularly useful for search and retrieval. There has been plenty of [discussion and dissent](https://nooscope.ai/) regarding “artificial intelligence” vs “cybernetics” over the years but regardless of interdisciplinary politics, both fields have grown considerably and are pretty ripe for a meaningful confluence manifest as semantic web infrastructure meets the algorithmic economy.  

In regards to classification and [representational models](https://healinggeneration.com/) a fruitful area of research is John Bennetts [General Systematics](https://en.wikipedia.org/wiki/Systematics_%E2%80%93_study_of_multi-term_systems). This is an integrative science for qualitative parametric groupings that has been in continuous development since 1955 and lives as an epistemic practice amongst a number of communities worldwide. Relevant collaborators of Bennetts were David Bohm, Buckminster Fuller and Stafford Beer. His tool for the 'classification of wholes' can be conceived of as a frame for constructing functional ontological groupings in a very elegant manner that seems appropriate for implementation on distributed ledger technology like [AD4M](https://ad4m.dev/).  

In regards to predictive capacities, the field of [active inferencing](https://mitpress.mit.edu/9780262045353/active-inference/) pioneered by the famed neuroscientist [Karl Friston](https://en.wikipedia.org/wiki/Karl_J._Friston) looks exceptionally promising. AI under through this lens is a means of understanding sentience from the perspective of minimising free energy or surprise and utilises a form of abductive or Bayseian reasoning. From the perspective of computer science, this can be thought of as a means of algorithmically extending a model’s resolution through statistical clustering.

# Relation to PL’s research activities

This applied research proposal is based around realisation of the semantic web for practical language evolution, which has a clear technical link to the open problem statement of “relaxing the traditional ‘web’ assumptions of a single origin to engage with the possibilities of pre-distributed CDN or content-addressed data.” It especially ties in well with recent work on [Generalised Impact Evaluators](https://research.protocol.ai/publications/generalized-impact-evaluators/) published by the [Network Goods](https://research.protocol.ai/groups/network-goods/) research team. The Hypercerts [community](https://hypercerts.xyz/) also seems particularly fertile in regards to discussions around model development and 'Digital Twins'. 

# Impact
> You can have a healthy fossil-fuel balance sheet, or a relatively healthy planet - but now that we know the numbers it looks like you cant have both. - Bill McKibben

Without an implementation plan this research proposal means little other than adding to a decaying body of cumulative research; traction requires implementation, a viable system with requisite variety and a sustaining community. To those ends we believe that coordinating development around the Regen Ledgers data-module and eco-credit modules are a pragmatic pathway and have submitted a complimentary governance proposal to the networks forum on commonwealth. We are essentially proposing an ecosystems level partnership between the Regen Network and Protocol Labs. 

At our present moment in history, accounting for impact in regenerative capital markets is particularly difficult because we are essentially trying to measure implicit values. Assuming the implementation plan linked above passes at the vote and is realised, we will actually be able to make such comparisons. Such technology is transformative enough to reshape entire capital markets in the long term by divesting capital towards proletariat stewards in need of resourcing working on Nature Based Solutions. We might look beyond that again to consider the possibilities for society that are available should such technology transform into a fully fledged semantic web; perhaps a [machine to machine economy](https://www.giordano.institute/the-machine-economy) may give rise to a “[sentient commons](https://gitlab.com/the-sentient-commons/sentient-commons-outline)”?

In regards to advancing the field it seems unlikely that a synthesis between General Systematics and Friston blankets has ever been undertaken; intuitively it feels like significant and meaningful breakthroughs can be made by combining the fields and applying towards good ends. This research consequentially extends into [Active Inference Ontology](https://zenodo.org/record/6320575#.Y-rclhPP2Ev) and [second order science](http://www.secondorderscience.org/). 

---

# Research strategy

Science can be classified both necessarily and sufficiently as three fundamental forms of reasoning; rational proof (deductive logic/Baconian method), empiric verification (inductive wisdom/Goethian method) and abductive insights that synthesise the known priors of means towards an end or outcome (Bayesian Inference). We seek to employ all three methods in our research. Below is a the application of a proposed methodology from H3uni with [strong explanatory power](https://en.wikipedia.org/wiki/Karl_Popper) and [living community of practice](https://en.wikipedia.org/wiki/Thomas_Kuhn).

1. **Research Process:** Facilitating discussions with [methodologies derived from general systematics](https://www.eventbrite.co.uk/e/the-art-of-creative-collaboration-tickets-450456656987) as applied research into the drivers of practical language evolution. Proof of concept testing as a "weave" on [weco.io](https://weco.io/p/3528) before moving to visual facilitation once the interface is complete.
2. **Research Methods:** Specific instantiations of systematics (like this outline) applied as an [active inference ontology](https://zenodo.org/record/6320575#.Y-hMMBPP2Es). Data sets from the Regen Network and Regen Registry. 
3. **Research Context:** Comparative study of the relevant domains:
	1.  Exhaustive review of General Systematics and Active Inference literature
	2.  Deepening research into the domains of Interaction design and representation
4. **Research Task:** Increasing the efficiency of predictors by comparing the total harmonic distortion of overlapping semantic perspectives assessed through the statistical measurement of linguistic clusters. This can take the form of testing General Systematics as one shot learning models.

---

# Milestones
### Milestone one: Specifications and reading
**Start Date:** 2023-04-06
**Deliverables:**
1. Submitting a Research proposal to Regen in parallel to this RFP-X while reading
2. Research on state of affairs and shared with community partners and date set for sense making
3. Presentation on the state of affairs and Public sense making session in '[consortium](https://momentum.odyssey.org/login)' format
4. Working with implementation partners to align on functional specifications
5. Public presentation of engineering documentation to Regen Community and Network Goods team
6. Signalling proposal is made to the network via an on chain mechanisms
7. Proposal passes or fails based on validator determinations

**Budget:** 
- $80k Sabbatical Research budget from Protocol Labs to LunarPunk_Labs
- Token grant from Regen Foundation to community partners

### Milestone Two: DAO Design
**Start Date:** 2023-07-17
**Deliverables:**
1. Convene discussions around DAO design and Tokenomic Mechanism and share in a group context
2. Practice the design and document the results with [digital technology](https://weco.io/s/lunarpunklabs/posts)
3. Presentation of suggested DAO pilot programme provided to community partners 
4. Working with place based community facilitators to align on practices and methodologies
5. Onboarding documentation compiled and shared online
6. Community completes discussion on DAO design as engineering on a pilot project begins
7. Updates submitted to Commonwealth, Protocol Labs and Regen community

**Budget:** 
- $25k Cash grant from RND inc. to LunarPunk_Labs
- Token delegation from Regen Foundation to community partners

### Milestone Three: Pilot Project(s)
**Start Date**
**Deliverables:**
1. Articulate the precise eco-credit methodology and share in a 'consortium' context
2. Connect with the Regen Registry team while applying the methodology technique, documenting the results with [digital technology](https://weco.io/s/lunarpunklabs/posts)
3. Presentation of pretotype results provided to pilot partners 
4. Working with place based community facilitators to align with and codify their practice
5. Documentation published on their precise method
6. Submission of methodology submitted for peer review
7. Expert review via the Regen Registry team or third party verifier

**Budget:** 
- 200k REGEN tokens with 1 year lockup from RND inc. to implementation partners
- $150

### Milestone Four: Tokenomics csDAO
**Start date**:
- Interface design for functionally encoding community conversations
- Describing general systematics as an AD4M 'perspective'
- Integrating Regen's data module as an AD4M 'language'
- Integrating Regen's eco-credit module as an AD4M 'perspective'

**Budget:** 
- 500k locked REGEN tokens to initiate the csDAO structure.
- $150,000 contribution from Protocol labs to DAO.

---
# Teams as Viable Systems Architecture
- **Purpose** :: Pilot Implementations :: [Regenerating Sonora](https://regeneratingsonora.org/) 
- **Intelligence** :: Logistics ::  [LunarPunk_Labs](Lunarpunklabs.org) 
- **Operations** :: Development :: [WeCo](WeCo.io)
- **Coordination Task** :: Design :: VIZN_Labs
- **Resourcing** :: Research :: [Sovereign Nature Initiative](https://sovereignnature.com/) 

# Prior Traction
- Odyssey 2020 SSI track winners
- GR15 Marketing
- Refi DAO founders circles
- Future Quest grant top 100 grantee
- GItcoin Verification Infrastructure bundle

# References
- [Complexity rising](https://necsi.edu/complexity-rising-from-human-beings-to-human-civilization-a-complexity-profile) 
- [Augmenting human intellect](https://www.dougengelbart.org/pubs/augment-3906.html)
- [Carbon tracker: two trillion dollars of stranded assets](https://carbontracker.org/reports/stranded-assets-danger-zone/)
- [Project Xanadu](https://en.wikipedia.org/wiki/Project_Xanadu)
- [Object Capabilities 101](https://www.youtube.com/watch?v=qZ2LltOmD5A&t)
- [Regen Ledger](https://www.regen.network/) 
- [Pillar Wallet](https://www.pillar.fi/)
- [Subconscious Network](https://subconscious.network/)
- [CEPTR](http://ceptr.org/). 
- [Nooscope: AI as Instrument of Knowledge Extractivism](https://nooscope.ai/)
- [Healing Generation](healinggeneration)
- [General Systematics](https://en.wikipedia.org/wiki/Systematics_%E2%80%93_study_of_multi-term_systems)
- [AD4M](https://ad4m.dev/) / [P3rspectivism](https://www.perspect3vism.org/)
- [Active inferencing](https://mitpress.mit.edu/9780262045353/active-inference/)
- [Karl Friston](https://en.wikipedia.org/wiki/Karl_J._Friston)
- [Generalised Impact Evaluators](https://research.protocol.ai/publications/generalized-impact-evaluators/)
- [Network Goods](https://research.protocol.ai/groups/network-goods/)
- [Hypercerts community](https://hypercerts.xyz/) 
- [Machine to machine economy](https://www.giordano.institute/the-machine-economy)
- [sentient commons](https://gitlab.com/the-sentient-commons/sentient-commons-outline)
- [Active Inference Ontology](https://zenodo.org/record/6320575#.Y-rclhPP2Ev) 
- [Second order science](http://www.secondorderscience.org/)
- [Karl Popper](https://en.wikipedia.org/wiki/Karl_Popper)
- [Thomas Kuhn](https://en.wikipedia.org/wiki/Thomas_Kuhn).
- [Art of creative collaboration](https://www.eventbrite.co.uk/e/the-art-of-creative-collaboration-tickets-450456656987)
- [WeCo](Weco.io)
- [Odyssey Momentum Platform](https://momentum.odyssey.org/login)
- [Methodology Testing](https://weco.io/s/lunarpunklabs/posts)
- [Regenerating Sonora](https://regeneratingsonora.org/) 
- [LunarPunk_Labs](Lunarpunklabs.org) 
- [WeCo](WeCo.io)
- [Sovereign Nature Initiative](https://sovereignnature.com/) 


# Extended Resources
- [Regen Request For Proposals](https://commonwealth.im/regen/discussion/7802-request-for-proposals-regen-tokenomics-upgrade)
- [Regen Registry Guide](https://library.regen.network/v/regen-registry-program-guide/regen-registry-overview/structure)
- [Emperors new Markov blanket](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/emperors-new-markov-blankets/715C589A73DDF861DCF8997271DE0B8C)
- [Active Inferrence ontology](https://zenodo.org/record/6320575#.Y-FQ0xPP2Ev)
- [Generalised Impact Evaluators](https://research.protocol.ai/publications/generalized-impact-evaluators/ngwhitepaper2.pdf)
- [Scientific Realism about Friston Blankets without literalism](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/scientific-realism-about-friston-blankets-without-literalism/E9DCE9EEA26AF82CE4977311B4973561)
- [Second Order Science; logic, strategies, methods](https://www.researchgate.net/publication/279324039_Second-order_Science_Logic_Strategies_Methods)
- [Beyond postnormal times: The future of creativity and the creativity of the future](https://www.sciencedirect.com/science/article/abs/pii/S0016328710002405)
- [Panarchy: Theory and Application](https://link.springer.com/article/10.1007/s10021-013-9744-2)  
- [Social–ecological hotspots mapping: A spatial approach for identifying coupled social–ecological space](https://www.sciencedirect.com/science/article/abs/pii/S0169204607002216)
- [Defining and measuring the social-ecological quality of urban greenspace: a semi-systematic review](https://link.springer.com/article/10.1007/s11252-015-0456-6)
- [Enhancing the Ostrom social-ecological system framework through formalization](https://www.ecologyandsociety.org/vol19/iss3/art51/)
- [Integrating sense of place into ecosystem restoration: a novel approach to achieve synergistic social-ecological impact](https://www.ecologyandsociety.org/vol23/iss4/art25/)
- [The healing-growth future of humanity: regenerative politics and crealectic care](http://uu.diva-portal.org/smash/get/diva2:1620901/FULLTEXT02.pdf)
- [Towards Ecological Economics](https://medium.com/regen-network/towards-ecological-economics-de0c035e622e)
- [Information technology is a mess](https://www.theregister.com/2023/01/30/hospital_legacy_systems_recovery/)
- [Leading researchers on stranded assets](https://www.smithschool.ox.ac.uk/)
- [Holonic Medium](https://docs.google.com/document/d/1hc7UMHlvaFpwaDPzcseTycUlHRIy1NlJpHfGQgB_c-I/edit#heading=h.nhvltdokqxbd)
- [Weco: An ontological design framework](https://docs.google.com/document/d/1ZvIr9r9hl4E1RU4t885TyuXW0gCpt2Ad4ieYOT--a90/edit)
- [Castela: The Citedel of Truth](https://docs.google.com/document/d/16FZnGeNaxPD32S_vvw5idHM0ULka_ObUpo1-c_x-LJU/edit)
- [Weco Explainer](https://www.youtube.com/watch?v=I6S61HejjzA "https://www.youtube.com/watch?v=I6S61HejjzA")
- [Weco Explainer](https://www.youtube.com/watch?v=zsOakAxOeb4 "https://www.youtube.com/watch?v=zsOakAxOeb4")
- [Purple Pill](purplepill.vision)
- [Manifest Collage](https://docs.google.com/presentation/d/1JOvhanx1Iy4z6bu0noRRpDxi0rZ4h3mVAoZNtDJi_Uk/edit#slide=id.p "https://docs.google.com/presentation/d/1JOvhanx1Iy4z6bu0noRRpDxi0rZ4h3mVAoZNtDJi_Uk/edit#slide=id.p")
- [Manifest creative brief](https://docs.google.com/presentation/d/1rBIwGO5mdqyNMtRM9PqhKCho-fm101Af4aQwbC2pfWs/edit#slide=id.g54e6c0941f_0_1320 "https://docs.google.com/presentation/d/1rBIwGO5mdqyNMtRM9PqhKCho-fm101Af4aQwbC2pfWs/edit#slide=id.g54e6c0941f_0_1320")
- [Manifest UI](https://docs.google.com/document/d/1JzESJ_2j7peR4cwzGeGZQoSjJjc2n7vX5AvK2SMUuvw/edit "https://docs.google.com/document/d/1JzESJ_2j7peR4cwzGeGZQoSjJjc2n7vX5AvK2SMUuvw/edit")