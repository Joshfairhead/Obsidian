Review Rubric:

1. A well-formed statement of the research problem and the proposed solution
2. Evidence that the applicant understands the current state of the art relevant to the research question. This may take the form of an annotated bibliography or a brief literature review. 
3. A clear explanation of how the proposed research program relates to Protocol Labs' current research activities, and a description of the foreseen impact of the work.
4. An outline of the research strategy to be employed in the project, including significant methods and tools, a timeline of key milestones with budgets and deliverables, and a statement of the expected objectives.
5. You may additionally wish to identify any of your current research collaborations that are particularly relevant to the proposed project.

---

# Semantic Networks for Practical Language Evolution

### [LunarPunk_Labs](lunapunklabs.org) - [University of the Third Horizon](h3uni.org)

1. **Research question**: How do we Increase relevance on the web and effectively bridge the gap from research to implementation?  

4. **Research problem statement**: Outperformance is retrieval time; to keep up with the [worlds rising complexity](https://necsi.edu/complexity-rising-from-human-beings-to-human-civilization-a-complexity-profile) we must improve the efficiency of our representational capacities to feed our capabilities of search and retrieval at the protocol level.  

3. **Proposed solution**: Semantically composable eco-credits; systemically structured Friston blankets used to create composable credit classes by representing community discourses as epistemologically transparent functional models. By providing precise algorithmic insights into relevant materials for [venture management and discovery](https://github.com/Joshfairhead/Obsidian/blob/main/Immanent/Projects/LunarPunk_Labs/Economics.md) we can harness market demand as a whole to drive vertical adoption of the technology stack, while also simultaneously divesting capital upstream to regenerative projects through the propagation of knowledge graphs. We might call this design ‘adaptive capital’ for simplicity or fit it under a pre-existing memeplex like ‘hypercerts’.

# Related work 

## Problem framing

The semantic web is politically a hard problem because it requires a confluence of factors to emerge across disciplines in a goldilocks zone of coalescence. The key question is what innovations are needed to bridge the gap between research and implementation?

## State of art(s)

Over the years there has been a plethora of research on the semantic web and related topics but from the perspective of this author centers around is Doug Englebarts “[Augmenting Human Intellect](https://www.dougengelbart.org/content/view/138/)” and his many other innovations at Xerox Parc. Thankfully these ideas are once again gaining the attention they dearly deserve; even with a fresh and funky twist!

**Interface Design**
Assuming the affordances of Englebarts architectures, his associate Ted Nelson conceived of [Project Xanadu](https://en.wikipedia.org/wiki/Project_Xanadu) in the 60’s, becoming a pioneer in the fields of representation and interaction design. His body of foundational research around ‘the memeplex’ now seems to be sprouting into a fresh implementation cycle as evident in ‘second brain’ style products like Obsidian. This is fantastic progress in a space that’s once again beginning to move fast, yet the field still has plenty of scope for development.

**Data Security and Network Integrity**
When considering a vision of a free and open internet that serves humanity, the most fundamental first principle to consider is the software security model. This model dictates a set of design affordances through the principle of inheritance. With the growing shift in preferences from centralized to decentralized computing, we have inadvertently started to re-adopt a [“capabilities”](https://www.youtube.com/watch?v=qZ2LltOmD5A&t) oriented security model at the network level. This architecture can be seen manifesting in the form of cryptographic tokens that are stored on distributed ledgers and controlled through wallet addresses - but it’s potential is mostly nascent and unrealised. 

**Algorithmic intelligence**
Between interfaces and distributed data storage lie algorithmic programmes; a primitive form of associative intelligence particularly useful for search and retrieval. There has been plenty of [discussion and dissent](https://nooscope.ai/) regarding “artificial intelligence” and “cybernetics” over the years but regardless of their interdisciplinary politics, both fields have grown considerably and are ripe for a meaningful confluence as the semantic web.  

In regards to classification, a fruitful area of research is John Bennetts [General Systematics](https://en.wikipedia.org/wiki/Systematics_%E2%80%93_study_of_multi-term_systems). This is a second order science for qualitative parametric groupings that has been in continuous development since 1955 amongst a number of communities worldwide. Relevant collaborators of his were Buckminster Fuller, David Bohm and Stafford Beer. His tool for classification can be conceived of as a frame for constructing functional ontological groupings in a very elegant manner that also seems suitable for implementation on [appropriate distributed ledger technology](https://ad4m.dev/). 

In regards to predictive capacities, the nascent field of [active inferencing](https://mitpress.mit.edu/9780262045353/active-inference/) pioneered by the famed neuroscientist [Karl Friston](https://en.wikipedia.org/wiki/Karl_J._Friston) looks exceptionally promising. AI under this lens is a means of understanding sentience from the perspective of minimizing free energy or surprise; a form of abductive or Bayseian reasoning. From the perspective of computer science, this can be thought of as a means of algorithmically extending a model’s [resolution](https://github.com/Joshfairhead/Obsidian/blob/main/Immanent/Projects/R3solution/R3solution.md) through statistical clustering.


# Relation to PL’s research activities

This research proposal is centered around the semantic web has a clear technical link to the open problem statement of “relaxing the traditional ‘web’ assumptions of a single origin to engage with the possibilities of pre-distributed CDN or content-addressed data.” It especially ties in well with recent work on [Generalised Impact Evaluators](https://research.protocol.ai/publications/generalized-impact-evaluators/) published from the [Network Goods](https://research.protocol.ai/groups/network-goods/) research group. The Hypercerts [community](https://hypercerts.xyz/) also seems particularly fertile in regards to discussions around model development and “Digital Twins”.

# Impact
> You can have a healthy fossil-fuel balance sheet, or a relatively healthy planet - but now that we know the numbers it looks like you cant have both. - Bill McKibben

Without an implementation plan this research proposal means pretty little, we need to generate traction which comes from marketing and technological development. To those ends we believe that coordinating development around the Regen Ledgers data-module and eco-credit modules are a pragmatic pathway and have submitted this governance proposal to the networks forum on commonwealth, along with a [background primer on ecosystem function from a market context](https://commonwealth.im/regen/discussion/9918-ecosystem-function-economics). 

At the moment accounting for impact in regenerative capital markets is particularly difficult from a quantitive standpoint as we are essentially trying to measure implicit values. Assuming the implementation plan linked above succeeds, we will actually be able to make such comparisons, which is a notion transformative enough to reshape entire capital markets; particularly to the financial benefits of proletariat stewards practicing Nature Based Solutions. Aside from these more grounded and pressing needs, we might consider the possibilities for society that are available should it transform into a fully fledged semantic web; perhaps a “[sentient commons](https://gitlab.com/the-sentient-commons/sentient-commons-outline)” or truely [Open Collective](https://opencollective.com/lunarpunk_labs) will emerge through interaction with our peers at [informal systems](https://informal.systems/)!

In regards to advancing the field, a synthesis between General Systematics and Friston blankets has never been undertaken, though an exhaustive literature review of cognition and wholeness has yet to be undertaken by the author. 

# Research strategy

In theory, science can be categorised both necessarily and sufficiently as three fundamental forms of reasoning; rational proof (deductive logic/Baconian method), empiric verification (inductive wisdom/Goethian method) and abductive insights that synthesise the known priors of means towards an end or outcome like Hume's Guillotine (Bayesian Inference). We seek to employ all three methods in our research. Below is a the application of a proposed methodology from H3uni with [strong explanatory power](https://en.wikipedia.org/wiki/Karl_Popper) and [living community of practice](https://en.wikipedia.org/wiki/Thomas_Kuhn).

1. **Research Process:** Facilitating discussions with [methodologies derived from general systematics](https://www.eventbrite.co.uk/e/the-art-of-creative-collaboration-tickets-450456656987) as applied research into the drivers of practical language evolution. Proof of concept testing as a "weave" on [weco.io](https://weco.io/p/3528).
   
2. **Research Methods:** Specific instantiations of systematics like this outline applied as an [active inference ontology](https://zenodo.org/record/6320575#.Y-hMMBPP2Es), data sets to include the Regen Network and Registry. 

4. **Research Context:** Comparative study of the relevant domains:
	1.  Exhaustive review of General Systematics and Active Inference literature
	2.  Deepening research into the domains of Interaction design and representation

4. **Research Task:** Increasing the semantic efficiency of LLMs by examining the total harmonic distortion of overlapping ontological perspectives assessed through the statistical measurement of linguistic clusters. 

In parallel it will be necessary to drive the implementation by championing the proposal and generating stakeholder buy in:
1.  Regen community calls
2.  Hypercerts community calls
3.  Network Goods community calls
4.  LunarPunk Labs community activation
5.  Active Inference Institute / Complexity Weekend calls

# Milestones
## M1: Proof of concept   

Date: 2020-01-01
Deliverables:
- Articulate methodology in a group context looking towards its further documentation
- Practice the methodology techniques and document the results with [digital technology](https://weco.io/s/lunarpunklabs/posts)
- Generate a research report of results to provide the pilot project 
- Pilot project experimentation
- Development of technology informed by research and results in the field



Long-form description… Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

## M2: <title> 

Date: 2020-01-01
Deliverables:
-   Deliverable 3
-   Deliverable 4

Long-form description… Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.



---


# References

[https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/emperors-new-markov-blankets/715C589A73DDF861DCF8997271DE0B8C](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/emperors-new-markov-blankets/715C589A73DDF861DCF8997271DE0B8C)

$1T stranded assets number: [https://carbontracker.org/climate-week-nyc-stranded-assets-and-stranded-liabilities-the-fossil-fuel-industry-is-failing-to-save-for-retirement/](https://carbontracker.org/climate-week-nyc-stranded-assets-and-stranded-liabilities-the-fossil-fuel-industry-is-failing-to-save-for-retirement/)

Leading research on stranded assets:
https://www.smithschool.ox.ac.uk/


---

From notes: 
- **Co2 in the atmosphere has now passed 400ppm and climate scientists have agree that the safe level to avoid climate catastrophe is 350ppm**
                 - 417ppm in 2020
             - To reduce the greenhouse gasses to 350ppm means cutting global Co2 emissions by 80% by 2020
             - The other important number to remember is the safe absolute amount of Co2 that we can emit into the atmosphere and still stay at a safe level. Thats a very large number; 565 gigatons (billions of tons) of Co2... but the important fact to remember is that this number represents only 20% of the reserves that the proven reserves that the fossil fuel company have in the ground and listed as assets that they plan to burn!
             - **So this means that to avoid global climate collapse the fossil fuel companies need to keep 80% of their assets (proven reserves) in the ground. **
             - This explains why big oil and big coal fight so hard against restrictions on carbon emissions, even to the extent of systematically denying climate science and orchestrating publicity campaigns against climate science and undermining it, because they don't want to turn to 80% of their assets into whats called **"stranded assets"**
             - **Once the financial markets know that 80% of these assets will stay in the ground, they're not worth anything - so the shares drop by 80%, which for them is a catastrophe of course!**
             - One of the most eloquent writers on climate change is [[Bill McKibben]] and in the systems view of life book we cite numerous articles of his - and he writes **"you can have a healthy fossil-fuel balance sheet, or a relatively healthy planet - but now that we know the numbers it looks like you cant have both."**
— 

Regen RFP: 

  
  

—- 
## Hacking

The two major fields of research that informs our inquiry into outperformance retrieval time are:  

[General Systematics](https://en.wikipedia.org/wiki/Systematics_%E2%80%93_study_of_multi-term_systems) is a second order science that has been in development since at least 1955 by the British scientist John Bennett. The field can be thought of as an epistemological framework for ontological design that rests adjacent to cybernetic control theories. 

[Active Inference](https://mitpress.mit.edu/9780262045353/active-inference/) is a means of understanding sentience from the perspective of minimizing free energy or surprise. It’s a form of abductive or Bayseian reasoning pioneered by the famed neuroscientist [Karl Friston](https://en.wikipedia.org/wiki/Karl_J._Friston).

[Information technology is a mess](https://www.theregister.com/2023/01/30/hospital_legacy_systems_recovery/), and [finding desirable results on the web is like searching for a needle in a Google whack](https://en.wikipedia.org/wiki/Dave_Gorman%27s_Googlewhack_Adventure). 

  

-   Explain how the problem relates to Protocol Labs’ [open problems](https://github.com/protocol/research/blob/master/README.md) or [recent research activities](https://research.protocol.ai/publications/). We seldom fund proposals without a clear technical link to one of our [active research groups](https://research.protocol.ai/groups/), so please indicate the group or researcher(s) that you consider the closest to your work.