Review Rubric:

1. A well-formed statement of the research problem and the proposed solution
2. Evidence that the applicant understands the current state of the art relevant to the research question. This may take the form of an annotated bibliography or a brief literature review. 
3. A clear explanation of how the proposed research program relates to Protocol Labs' current research activities, and a description of the foreseen impact of the work.
4. An outline of the research strategy to be employed in the project, including significant methods and tools, a timeline of key milestones with budgets and deliverables, and a statement of the expected objectives.
5. You may additionally wish to identify any of your current research collaborations that are particularly relevant to the proposed project.

---

# Semantic Networks for Practical Language Evolution

### [LunarPunk_Labs](lunapunklabs.org) - [University of the Third Horizon](h3uni.org)

1. **Research question**: How do we increase relevance on internet to aid the realisation of knowledge into understanding while effectively bridging the gap from research to implementation?  

2. **Research problem statement**: To keep up with the [worlds rising complexity](https://necsi.edu/complexity-rising-from-human-beings-to-human-civilization-a-complexity-profile) we'll need to improve deepen our human capacities for representation and interpretation by [augmenting our intellect](https://www.dougengelbart.org/pubs/augment-3906.html). 

3. **Proposed solution**: An ecosystem level partnership between Protocol Labs and Regen Ledger to bootstrap Semantic Impact Markets with 'adaptive capital'. We propose systematically structured conversation graphs as a means of classifying parametric groupings into Friston blankets to enable semantically composable eco-credits as 'hypercerts'. Framing model metatdata as functional  geometries to group such paramaters provides epistemological transparency; a necessity for both governance and scientific research. We propose further transdiciplinary research and applied practice into the nuances of implementing such a task.


# Related work 
## Problem Framing as Market Hypothesis
Before innovating on such financial technology, let's articulate some working assumptions about the market in order to progressively approximate some enabling constraints. Let's start with the major market participants and then examine the forces which move them.

#### Participants (Who)
> - Alpha investors; risk-on. Seeks return on investment. Quantifiers.
> - Beta investors; risk-off. Seeks wealth preservation. Qualifiers.

Our first assumption is that there are two broad sets of market participants that have different risk appetites. The first set of participants are alpha investors and the second set are beta investors. The former have a high risk appetite and the latter a low risk appetite; one set seeks to beat the market and the other desires to 'be' the market. 

Animating these actors, let's characterise our alpha investors as hedge funds and our beta investors as pension funds. Here we notice that the former is incentivised by carrots in the form of returns, while the latter does it's best to avoid the stick of regulation and corporate responsibility. Note that costs / risks / benefits moves both sets of participants at a fundamental level. Blue funds or impact markets mediate this by opening up new markets for both appetites.

#### Institutional Constraints (Why)
The next assumption about markets is that there are $5T of stranded assets that are traded on Wall St. books. These assets take multiple forms but generally speaking they are below ground commodities like coal, oil and gas, which can't be extracted due to planetary boundary conditions. As these commodities have no intrinsic value their existence essentially depends on an irrational market; when it sobers up these assets will need to be 'struck from the books'.  

Both investor profiles are consequentially searching for new stores of value; a phenomena observable through their embrace of qualitative indicators such as ESGs. As always, there is a deal of controversy about the efficacy of these specific values and though imperfect in themselves ESG's have sufficient traction to suffice as a general set of heuristics that help make intervention points more evident.

Regardless of the specific values, it's apparent that both of our investor profiles are caught in a dilemma of reconciling qualitative values with quantitive measures. Market participants have plenty of motivation to divest their capital but they lack profitable investment vehicles that can account for a given set of values in a quantifiable manner. 

#### Economic Pathways (How)
Provisioning divestment options consequentially requires the opening of new markets and a set of market makers that hold a completely different mentality from what we know and have seen before. Instead of externalising costs, as entrepreneurs have done in the past, the demands upon the new breed of market makers will be to supply products that instead internalise and account for values. This is essentially a $5T market opportunity for blue funds / impact capable of facilitating such a transformation; the question is what kind of products would such a marketplace either need or want? 

Examining economics in terms of nouns and verbs helps us to distinguish **capital** from **currencies**. Currencies (current-sees) are measures of value flow across time, whereas capital arises from integrating these flows. In that regard we see two forms of measure; the qualitative and quantitive.

From the quantitive perspective, input measurements with the potential for aggregation might include GIS data, bio-acoustics, nutrient density or Brix values ect. These measures are useful at the data level but aggregating them becomes difficult due to a lack of interoperable and composable standards, which is also an issue for the qualitative accounting of heuristics like ESGs. The representation, organisation and translation of such values is a scientific and technical challenge that is only just becoming solvable. 

When it comes to these scientific and technological realms, Markov / Friston blankets help in this matter by providing a means to bound unwieldy complexity into something more manageable. These serve as a base medium from which higher order systems can be assembled. Essentially, this means that we can now compose data streams into information classes to further build more structured and systematic relationships.

This probably satisfies our alpha investors who are seeking volatility and consequentially look towards more complex speculative instruments in the pursuit of their asymmetric returns. This is where the notion of 'adaptive capital' starts to become an interesting pathway. 

#### Adaptive capital (What)
Paradigms like natural capital accounting and payments for ecosystem services have tended towards controversy because much of life's intrinsic value is implicit in it's experientially healthy functionality. This complex behaviour is extremely hard to package into a product so we might more easily bootstrap new markets from legacy paradigms on new infrastructure. From carbon, to co-benefits... to adaptive living capital. 

As far as instrument design goes, the representation of noun like products such as carbon is relatively easy. Moving beyond such basic designs we can augment these classic commodities with co-benefits, and beyond that again towards the real-time representation of ecological state. Such a future requires dynamic schemas.

For example, if the ESG heuristics (or SDGs ect) are considered to be our markets aspirational values, we still need to measure, account for and evaluate progress towards them. Such functionality is a necessary substrate to enable the representation of complex and adaptive capital. For such vehicles to arise would require the composition of at least several interoperable standards.

- Ground: Sensing Data (Monitoring, Reporting, Verification)
- Ideal: Evaluation criterea (e.g Environmental, Social, Governance)
- Instrumental: Blockchain accounting (Resource, Event, Agent) 
- Directive: Community culture (Agents, Languages, Perspectives)

To represent these standards in a composible way themselves, we can look back to markov blankets as a form of binding agent that allows for nesting at various levels of scale. The above represents a core feature set. Significantly, these blankets can give rise to a number of conceptual primitives around impact markets; namely conversation graphs that can represent certifications or evaluation criterea, while they are also relevant as an API layer for loading arbitrary input schemas (from sensors or other interfaces).

- Purpose: Ledger Based Accounting
- Values: Impact evaluators
- Significance: Systematised Markov Blankets for Active Inferencing
- Facts: Impact certificates
- Resource: Sensing / sensors

This kind of architecture is general enough to be instantiated for any given application; be it simple commodities or a chain of complex systems. In this manner we can consider markov blankets to be a form of interface that enables arbitrary input data to be composed, accounted for, certified and evaluated. 

Looking back to our investor needs, we note that such a system can adapt to requirements across scales without disruption; from local monitoring, reporting and verification data to global market values like ESGs. Because there is an aggregation of live data feeds getting evaluated against an ideal state, there is also an investible delta for market participants to profit from. 

Accounting for a set of articulated values and then evaluating these against the free energy principal also makes the vehicle an unenclosable carrier; that which doesn't trend towards harmony fails as an investment vehicle, while that which does succeeds. Regenerative activity subsequently fits to financial return and speculative market activity consequentially funnels capital upstream to proletariats working on regenerative projects in the long term, while also allowing investors seeking to divest to earn delta in the short term to drive the process.

Beyond market conditions the semantic web is a hard problem because it requires a confluence of factors to emerge across disciplines. The key question is what innovations are needed to bridge the gap between research and implementation?

## State of art(s)

Over the years there has been a plethora of research on the semantic web and related topics but from the perspective of this author centres around is Doug Englebarts “[Augmenting Human Intellect](https://www.dougengelbart.org/content/view/138/)” and his many other innovations at Xerox Parc. Thankfully these ideas are once again gaining the attention they dearly deserve; even with a fresh and funky twist!

#### **Interface Design**
Assuming the affordances of Englebarts architectures, his associate Ted Nelson conceived of [Project Xanadu](https://en.wikipedia.org/wiki/Project_Xanadu) in the 60’s, becoming a pioneer in the fields of interaction design and representation. His body of foundational research around ‘the memeplex’ now seems to be sprouting into a fresh implementation cycle as evident in ‘second brain’ style products like Obsidian. This is fantastic progress in a space that’s once again beginning to move fast, 

#### **Data Security and Network Integrity**
When considering a vision of a free and open internet that serves humanity, the most fundamental first principle to consider is the software security model. This model dictates a set of design affordances through the principle of inheritance. With the growing shift in preferences from centralized to decentralized computing, we have inadvertently started to re-adopt a [“capabilities”](https://www.youtube.com/watch?v=qZ2LltOmD5A&t) oriented security model at the network level. This architecture can be seen manifesting in the form of cryptographic tokens that are stored on [distributed ledgers](https://www.regen.network/) and controlled through wallet addresses. The progress has been rapid from our shallow time frame but the field still has plenty of [scope for development](https://subconscious.network/) resting upon [dormant potentials](http://ceptr.org/). 

#### **Algorithmic 'intelligence'**
Between interfaces and distributed data storage lie algorithmic programmes; a primitive form of associative intelligence particularly useful for search and retrieval. There has been plenty of [discussion and dissent](https://nooscope.ai/) regarding “artificial intelligence” and “cybernetics” over the years but regardless of interdisciplinary politics, both fields have grown considerably and are pretty ripe for a meaningful confluence manifest as semantic web infrastructure meets the algorithmic economy.  

In regards to classification a fruitful area of research is John Bennetts [General Systematics](https://en.wikipedia.org/wiki/Systematics_%E2%80%93_study_of_multi-term_systems). This is an integrative science for qualitative parametric groupings that has been in continuous development since 1955 and lives as an epistemic practice amongst a number of communities worldwide. Relevant collaborators of Bennetts were David Bohm, Buckminster Fuller and Stafford Beer. His tool for the 'classification of wholes' can be conceived of as a frame for constructing functional ontological groupings in a very elegant manner that seems appropriate for implementation on distributed ledger technology like [AD4M](https://ad4m.dev/).  

In regards to predictive capacities, the field of [active inferencing](https://mitpress.mit.edu/9780262045353/active-inference/) pioneered by the famed neuroscientist [Karl Friston](https://en.wikipedia.org/wiki/Karl_J._Friston) looks exceptionally promising. AI under through this lens is a means of understanding sentience from the perspective of minimizing free energy or surprise and utilises a form of abductive or Bayseian reasoning. From the perspective of computer science, this can be thought of as a means of algorithmically extending a model’s [resolution](https://github.com/Joshfairhead/Obsidian/blob/main/Immanent/Projects/R3solution/R3solution.md) through statistical clustering.

# Relation to PL’s research activities

This applied research proposal is based around realisation of the semantic web for practical language evolution, which has a clear technical link to the open problem statement of “relaxing the traditional ‘web’ assumptions of a single origin to engage with the possibilities of pre-distributed CDN or content-addressed data.” It especially ties in well with recent work on [Generalised Impact Evaluators](https://research.protocol.ai/publications/generalized-impact-evaluators/) published by the [Network Goods](https://research.protocol.ai/groups/network-goods/) research team. The Hypercerts [community](https://hypercerts.xyz/) also seems particularly fertile in regards to discussions around model development and “Digital Twins”.

# Impact
> You can have a healthy fossil-fuel balance sheet, or a relatively healthy planet - but now that we know the numbers it looks like you cant have both. - Bill McKibben

Without an implementation plan this research proposal means little other than adding to a deaying body of cumulative research, traction requires implementation and a sustaining community. To those ends we believe that coordinating development around the Regen Ledgers data-module and eco-credit modules are a pragmatic pathway and have submitted a complimentary governance proposal to the networks forum on commonwealth. We are essentially proposing an ecosystems level partnership between the Regen Network and Protocol Labs. 

At our present moment in history, accounting for impact in regenerative capital markets is particularly difficult because we are essentially trying to measure implicit values. Assuming the implementation plan linked above passes at the vote and is realised, we will actually be able to make such comparisons. Such technology is transformative enough to reshape entire capital markets in the long term by divesting capital towards proletariat stewards in need of resourcing for Nature Based Solutions. We might look beyond to consider the possibilities for society that are available should such technology transform into a fully fledged semantic web; perhaps a [machine to machine economy](https://www.giordano.institute/the-machine-economy) will give rise to a “[sentient commons](https://gitlab.com/the-sentient-commons/sentient-commons-outline)”?

In regards to advancing the field it seems unlikely that a synthesis between General Systematics and Friston blankets has ever been undertaken, but intuitively feels like significant and meaningful breakthroughs can be made by combining the fields and applying them for good cause. This is an [Active Inference Ontology](https://zenodo.org/record/6320575#.Y-rclhPP2Ev) or [second order science](http://www.secondorderscience.org/). 

---

# Research strategy

Science can be categorised both necessarily and sufficiently as three fundamental forms of reasoning; rational proof (deductive logic/Baconian method), empiric verification (inductive wisdom/Goethian method) and abductive insights that synthesise the known priors of means towards an end or outcome like Hume's Guillotine (Bayesian Inference). We seek to employ all three methods in our research. Below is a the application of a proposed methodology from H3uni with [strong explanatory power](https://en.wikipedia.org/wiki/Karl_Popper) and [living community of practice](https://en.wikipedia.org/wiki/Thomas_Kuhn).

1. **Research Process:** Facilitating discussions with [methodologies derived from general systematics](https://www.eventbrite.co.uk/e/the-art-of-creative-collaboration-tickets-450456656987) as applied research into the drivers of practical language evolution. Proof of concept testing as a "weave" on [weco.io](https://weco.io/p/3528).
2. **Research Methods:** Specific instantiations of systematics like this outline applied as an [active inference ontology](https://zenodo.org/record/6320575#.Y-hMMBPP2Es), data sets to include the Regen Network and Registry. 
4. **Research Context:** Comparative study of the relevant domains:
	1.  Exhaustive review of General Systematics and Active Inference literature
	2.  Deepening research into the domains of Interaction design and representation
4. **Research Task:** Increasing the semantic efficiency of LLMs by examining the total harmonic distortion of overlapping ontological perspectives assessed through the statistical measurement of linguistic clusters. 

In parallel it will be necessary to drive the implementation by championing the proposal and generating stakeholder buy in:
1.  Regen community calls
2.  Hypercerts community calls
3.  Network Goods community calls
4.  LunarPunk Labs community activation
5.  Active Inference Institute / Complexity Weekend calls

---

# Milestones
### M0: Meta
**Start Date:** NOW!
**Deliverables:** 
1. Specs
2. Design
3. Pilot project
4. Tokenomics DAO
5. Perfected designs
6. Planned product
7. Quality control

### Milestone one: Specifications and reading
**Start Date:** 2023-04-06
**Deliverables:**
1. Submitting a Research proposal to Regen in parallel to this RFP-X while reading
2. Research on state of affairs and shared with community partners and date set for sense making
3. Presentation on the state of affairs and Public sense making session in 'consortium' format
4. Working with implementation partners to align on functional specifications
5. Public presentation of engineering documentation to Regen Community and Network Goods team
6. Signalling proposal is made to the network via an on chain mechanisms
7. Proposal passes or fails based on validator determinations

**Budget:** 
- $35k Research budget from Protocol Labs to LunarPunk_Labs
- Token grant from Regen Foundation to community partners

### Milestone Two: DAO Design
**Start Date:** 2023-07-17
**Deliverables:**
1. Convene discussions around DAO design and Tokenomic Mechanism and share in a group context
2. Practice the design and document the results with [digital technology](https://weco.io/s/lunarpunklabs/posts)
3. Presentation of suggested DAO pilot programme provided to community partners 
4. Working with place based community facilitators to align on practices and methodologies
5. Onboarding documentation compiled and shared online
6. Community completes discussion on DAO design as engineering on a pilot project begins
7. Updates submitted to Commonwealth, Protocol Labs and Regen community

**Budget:** 
- $25k Cash grant from RND inc. to LunarPunk_Labs
- Token delegation from Regen Foundation to community partners

### Milestone Three: Pilot Project(s)
**Deliverables:**
1. Articulate the precise eco-credit methodology and share in a 'consortium' context
2. Connect with the Regen Registry team while applying the methodology technique, documenting the results with [digital technology](https://weco.io/s/lunarpunklabs/posts)
3. Presentation of pretotype results provided to pilot partners 
4. Working with place based community facilitators to align with and codify their practice
5. Documentation published on their precise method
6. Submission of methodology submitted for peer review
7. Expert review via the Regen Registry team or third party verifier

**Budget:** 
- Protocol Labs contributions to community partners
- 200k REGEN tokens with 1 year lockup from RND inc. to implementation partners

### Milestone Four: Tokenomics csDAO
**Budget:** 
- 500k locked REGEN tokens to initiate the csDAO structure.
- Contributions from Protocol Labs to sustain traction

#### Milestone Five: Engineering
- Interface design for functionally encoding community conversations
- Describing general systematics as an AD4M 'perspective'
- Integrating Regen's data module as an AD4M 'language'
- Integrating Regen's eco-credit module as an AD4M 'perspective'

**Budget**: TBD

#### Milestone Six: Perfected Designs
- Anchoring partner data on chain with the Regen data module
- Minting eco-credits for pilot project partners

**Budget**: TBD

#### Milestone Seven: Quality Control
- Issuing general systematics as a semantic credit class upon Registry Governance sign off.

**Business Model**
- Template instantiation of credit classes for generic methods
- Bespoke consulting for specific project demands

---
# Teams as Viable Systems Architecture
- **Purpose** :: Pilot Implementation :: [Regenerating Sonora](https://regeneratingsonora.org/) 
- **Intelligence** :: Logistics & Coordination ::  [LunarPunk_Labs](Lunarpunklabs.org) 
- **Operations** :: Development :: [WeCo](WeCo.io)
- **Coordination Task** :: Design :: VIZN_Labs
- **Resourcing** :: Research :: [Sovereign Nature Initiative](https://sovereignnature.com/) 

# Traction
- GR15 Marketing
- Refi DAO founders circles
- Future Quest grant top 100 grantee
- GItcoin Verification Infrastructure bundle

# References
- [Emperors new Markov blanket](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/emperors-new-markov-blankets/715C589A73DDF861DCF8997271DE0B8C)
- [Scientific Realism about Friston Blankets without literalism](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/scientific-realism-about-friston-blankets-without-literalism/E9DCE9EEA26AF82CE4977311B4973561)
- [Information technology is a mess](https://www.theregister.com/2023/01/30/hospital_legacy_systems_recovery/)
- [Panarchy: Theory and Application](https://link.springer.com/article/10.1007/s10021-013-9744-2)  
- [Robert Knowles, The Leadership Dance](https://www.google.com/search?q=the+leadership+dance+enneagram&client=firefox-b-d&sxsrf=AJOqlzXh833qcoeOFlFluNnHn560XoQ1IA:1675883705422&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjet8in0Yb9AhUGU6QEHSIgDi0Q_AUoAnoECAEQBA&biw=1440&bih=709&dpr=1#imgrc=XG24T0-zMmWY9M)
- [Deep Time Walk](https://www.deeptimewalk.org/)  
- [Charles Langmuir](https://www.youtube.com/watch?v=1srN5_IEXK8) 
- [Charles Langmuir 2](https://youtu.be/EtSdJjbtqNw)
- [Futures Journal](https://www.sciencedirect.com/journal/futures)
- [Beyond postnormal times: The future of creativity and the creativity of the future](https://www.sciencedirect.com/science/article/abs/pii/S0016328710002405)
- [Second Order Science; logic, strategies, methods](https://www.researchgate.net/publication/279324039_Second-order_Science_Logic_Strategies_Methods)
- [Regen Registry Guide](https://library.regen.network/v/regen-registry-program-guide/regen-registry-overview/structure)
- [LunarPunk Weco channel](https://weco.io/s/lunarpunklabs/posts)
- [Regen Request For Proposals](https://commonwealth.im/regen/discussion/7802-request-for-proposals-regen-tokenomics-upgrade)
- [Gaia BioHabitat Commons](https://docs.google.com/presentation/d/13xWKMRdfa1vJauJCn8SQq9fQqP9EEVJOowg78PU9hwM/edit#slide=id.g14d6de67000_0_617)
- [Blockscience propaganda](https://docs.google.com/presentation/d/1xvr_47iPlf1FTx7O2irqBGMCo-Z_7qdU/edit#slide=id.g89d5288067a441a_10)
- [Facets Journal](https://www.facetsjournal.com/doi/10.1139/facets-2020-0114)
- [Social–ecological hotspots mapping: A spatial approach for identifying coupled social–ecological space](https://www.sciencedirect.com/science/article/abs/pii/S0169204607002216)
- [Defining and measuring the social-ecological quality of urban greenspace: a semi-systematic review](https://link.springer.com/article/10.1007/s11252-015-0456-6)
- [Enhancing the Ostrom social-ecological system framework through formalization](https://www.ecologyandsociety.org/vol19/iss3/art51/)
- [Integrating sense of place into ecosystem restoration: a novel approach to achieve synergistic social-ecological impact](https://www.ecologyandsociety.org/vol23/iss4/art25/)
- [Weco: An ontological design framework](https://docs.google.com/document/d/1ZvIr9r9hl4E1RU4t885TyuXW0gCpt2Ad4ieYOT--a90/edit)
- [The healing-growth future of humanity: regenerative politics and crealectic care](http://uu.diva-portal.org/smash/get/diva2:1620901/FULLTEXT02.pdf)
- [Castela: The Citedel of Truth](https://docs.google.com/document/d/16FZnGeNaxPD32S_vvw5idHM0ULka_ObUpo1-c_x-LJU/edit) - generating conversation graphs
- [Holonic Medium](https://docs.google.com/document/d/1hc7UMHlvaFpwaDPzcseTycUlHRIy1NlJpHfGQgB_c-I/edit#heading=h.nhvltdokqxbd)
- [Towards Ecological Economics](https://medium.com/regen-network/towards-ecological-economics-de0c035e622e)
- [The emporers new markov blanket](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/emperors-new-markov-blankets/715C589A73DDF861DCF8997271DE0B8C)
- [Active Inferrence ontology](https://zenodo.org/record/6320575#.Y-FQ0xPP2Ev)
- [Generalised Impact Evaluators](https://research.protocol.ai/publications/generalized-impact-evaluators/ngwhitepaper2.pdf)
- PurplePill.vision
- [$1T stranded assets number](https://carbontracker.org/climate-week-nyc-stranded-assets-and-stranded-liabilities-the-fossil-fuel-industry-is-failing-to-save-for-retirement/)
- [Leading researchers on stranded assets](https://www.smithschool.ox.ac.uk/)
- [Manifest Collage](https://docs.google.com/presentation/d/1JOvhanx1Iy4z6bu0noRRpDxi0rZ4h3mVAoZNtDJi_Uk/edit#slide=id.p "https://docs.google.com/presentation/d/1JOvhanx1Iy4z6bu0noRRpDxi0rZ4h3mVAoZNtDJi_Uk/edit#slide=id.p")
- [Manifest creative brief](https://docs.google.com/presentation/d/1rBIwGO5mdqyNMtRM9PqhKCho-fm101Af4aQwbC2pfWs/edit#slide=id.g54e6c0941f_0_1320 "https://docs.google.com/presentation/d/1rBIwGO5mdqyNMtRM9PqhKCho-fm101Af4aQwbC2pfWs/edit#slide=id.g54e6c0941f_0_1320")
- [Manifest UI](https://docs.google.com/document/d/1JzESJ_2j7peR4cwzGeGZQoSjJjc2n7vX5AvK2SMUuvw/edit "https://docs.google.com/document/d/1JzESJ_2j7peR4cwzGeGZQoSjJjc2n7vX5AvK2SMUuvw/edit")
- [Weco Explainer](https://www.youtube.com/watch?v=I6S61HejjzA "https://www.youtube.com/watch?v=I6S61HejjzA")
- [Weco Explainer](https://www.youtube.com/watch?v=zsOakAxOeb4 "https://www.youtube.com/watch?v=zsOakAxOeb4")
- [BLUR](https://gm.xyz/c/CryptoNews/ae2c438e-0ee8-4f76-a434-c07466f2ac93)



or "[Open Collective](https://opencollective.com/lunarpunk_labs)" will emerge through interaction with our peers at [informal systems](https://informal.systems/) 