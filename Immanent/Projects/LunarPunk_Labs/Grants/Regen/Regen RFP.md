### Meta Process / Narrative
- Holonically speaking each step contains a further 7~ steps within it. 

1) Specs
2) Design
3) Pilot sample
4) Product/Market/Management
5) Perfected designs
6) Planned product
7) Quality control

---
# Proposal: "REGEN 2.0: Adaptive Capital "

## Background
To briefly preface this proposal submission with some context, the team at LunarPunk_Labs have been focused on the realisation of the semantic web for the past 4 years. As a distributed team we have previously won the digital identity track at the worlds largest ai & blockchain hackathon and specialise in systematic frameworks (aka functional ontologies). Weco on the other hand have been building an open social graph for several years and have developed "The Glass Bead Game" as an interface for a wisdom commons. Their work to date has previously been funded by Eric Harris Brown (of CEPTR). 

## Specifications as constraints
Nature Based Solutions are defined by the Regen Registry in the following way:

> Actions to protect, regeneratively manage and restore natural or modified ecosystems that address societal challenges effectively and adaptively, simultaneously providing human well-being and biodiversity benefits”.

Consequentially, "Adaptive Capital" is a proposition for valuing living ecosystems through multi-perspective architecture and the free energy principal; a means of integrating quantitive measures with qualitative values and outcomes. For such a project to find traction need to consider the existential domains of markets, science and technology; while holding in mind the essential values of people, planet and protocols. Let's explore:

**Market Assumptions**
The notion that markets are seeking pathways for divestment from degenerate commodities to more regenerative investment vehicles is getting wider traction. However the divesment is constrained by a lack of said pathways. We confidently assert this as it's known that there are $5T of "stranded assets" trading on Wall St. books, which in our opinion represents a transformation opportunity thats global in scale - provided we can address their pain points with integrity. [[Economics]]

**Scientific Assumptions**
When it comes to addressing the markets with integrity, we need to incorporate truth claims. There are two primordial forms of scientific reasoning; rational proof (deductive knowledge/Baconian method) and empiric verification (inductive wisdom/Goethian method). Regenerative science should in principal integrate both approaches to making Truth claims through abductive reasoning based on known priors (Bayesian inference). Such truth claims are essentially perspectives, which brings up questions of frame and representation; according to Khun science is a community of practice, while according to Popper it's about the explanatory power of a framework. [Ontological design](https://medium.datadriveninvestor.com/the-manifesto-of-ontological-design-7fdb19169107?gi=8c7bbd1fb970).  

**Technological Assumptions**
From a practical standpoint, the story of computers starts with Claude Shannons binary information theory of 1's and 0's, but beyond this there are new innovations which abstract the domain of information to a triple of "agents, languages and perspectives" where agents, speaking their language of preference, express perspectives on 'Truth'. 

As a technical architecture, this foundational 'meta ontology' allows us to encode other frameworks as languages, and in particular we believe that encoding "general systematics" is a transparent epistemology that can act as a functional backbone for modelling any scenario. 

Applied at the interface level these frames can be used to generate a consistent set of active inference models that enable the encoding of practice based methodologies, eco-credits, accounting methodologies, evaluation criteria, sensor networks APIs, DAOs and beyond. Such architecture is particularly elegant as it enables semantic translation and ad hoc composibility.

## General Technical Infrastructure
As far as necessary infrastructure design goes, there are three technical mechanisms that we can lean on in relation to our goal of integrating quantity with quality:
- Impact evaluators (+)
- Markov blankets (=)
- Impact certificates (-)

Markov blankets act as a form of general substrate and which can then be further systematised with **metadata** to enable semantic interoperability - this is a highly general medium that is analogus to merkle trees and hash graphs. In Regens case this technical infrastructure is represented by the data module.

An Impact certificate essentially articulates a methodology in a machine readable format - these certificates represent a means, while evaluation criteria codified in a similar format of parametric groupings can express values as ends. For example, when it comes to open science, there is a movement towards making papers more accessible by encoding them as 'conversation graphs' (in a geometry of "source, question, claim, proof"). 

Taking such a concept one step further it's easy enough to imagine a form of bespoke consulting where any conversation is represented as functional geometries that aid the processes of communal understanding. When the discussion reaches consensus (on Credit methodology or class, DAO design, evaluation criteria etc.) we can use the interface to easily anchor data on chain. Any subsequent discussion (with or with out a facilitator) can be updated through such an interface and easily merged. This data can be aggregated as a form of capital and issued as eco-credits, which would help democratise access to technology in a significant way. Such a process can even be gamified to make the process fun and rewarding!

From the interface level comes the functional specifications for chain integration. Using the AD4M ontology we can use general systematics to describe a set of metadata standards. We then describe both the data module and eco-credit modules in this 'language' to make them functionally compatible. For added precision, we may wish to add other ontologies for translating quantity (data module claims) to quality (eco-credit attestations). 

Resource, Event, Agent is an accredited accounting ontology designed for on the ground distributed supply chains; impact evaluation. At the opposite end of the spectrum we can leverage Monitoring, Reporting and Verification as evaluation criteria for impact certificates. The elegasre of this design is that if these standards are changed or extended, they can be easily assimilated, updated or recomposed. 

For example we can extend the triadic geometry MRV to be a tetradic geometry for more detailed resolution. The following was articulated by the dMeter community:
- Directive: Human-sensing (Personal data stores, phone images, self reported data)
- Instrumental: Remote-sensing (IOT sensors, devices)
- Ideal: Sky-sensing (satellite, drones, aerial)
- Ground: Reputation-sensing (identity, community trust)

Such an extension has many overlaps with REA accounting and the above frame can be superimposed to increase the resolution of evaluation criteria. 

---
## Specific Tokenomic Mechanisms
The above is general infrastructure for composing specific credits. The particular credit design is dependent on the parametric groupings instantiated around a use case or pilot project. To bring these technologies to market requires pilot projects. 

There are obviously a number of [great projects](http://purplepill.vision/) in the [Regen ecosystem](https://regennetwork.notion.site/Built-On-Regen-Network-c6266114116842e389258747454f9f07) that would stand to benefit from such composable designs and we're keen to partner based on capacity. Our preference is to work closely with our existing partners at Regenerating Sonora to build out a simple proof of concept as the conditions are pretty fertile; they have LEHR gardens, a community centre with a blockchain learning centre and high school tech club working with Arudino sensors. 

#### Regenerating Sonora Use Case
Starting from the LEHR gardens, we assess possibilities. It's decided that the quintessential step forward is to automate the gardens water timers. A group of local high schoolers automate the timers using their Arduino kits. Through the Weco interface, these data level streams are hooked up to a storage medium of choice like Filecoin Green and anchored with the Regen DataModule. 

As the students add other sensors to augment the timers with feedback loops, these are added to the systematic interface. These feedback loops are assessed using active inferencing; are the gardens growing better with the automation or worse? Student determinations may well be best guesses, rather than institutional best practice, but a credit can be issued none the less using the eco-credit module. 

At some point in the future a soil scientist recommends measuring Brix values instead of the students best guess, and someone smart also suggests tracking pollinators. The students put in new sensors and update their eco-credits underlying methodology using the geometric interface. Active inference engines suggest that these changes are beneficial to the gardens in reference to a stipulated outcome of vegetation growth, which is then automatically published on chain as supporting data. Consequentially the credit gains value in the market and efforts are rewarded.

As the student group develops a reputation for making strong decisions around the growing LEHR gardens, it becomes apparent that this is an investment opportunity to market participants. The students reserve pool grows in value thanks to this speculative activity, and consequentially so have the funds to scale operations into new locations. Both investors and the wider Regenerative movement benefit!

But that's not all, the students realise that the LEHR gardens have been an anchor point around which the community practices have grown which has brought wellbeing and vibrancy to their community. They use the interface to codify their activities as a state model, which they use to augment their commodity model as co-benefits. This reveals the more implicit aspects of their work, which is typically invisible to the bottom line of profits. These indicators help guide ethical investors and corporate responsibility funds to their project. 

### Community Capital
An example methodology our students might use for codifying their co-benefits is the H3uni framework deployed on the current course "The art of creative collaboration". This particular practice based methodology groups eight sets of parameters under four framing conditions. 

Framing conditions:
- Directive: Process
- Instrumental: Method
- Ideal: Task
- Ground: Context

Paramater Groupings:
- Self awareness
- Empathetic appreciation
- Group dynamics
- Interactive skill
- Cognitive framing
- Visualisation skill
- Perceiving qualities
- Mental repatterining

This particular methodology is currently being demonstrated as both the H3uni course with video documentary evidence AND being discussed amongst our teams on WeCo.io as a weave (chains of 1min audio recordings / 140 character cards in a sequence). You can keep up with the teams progress [here](https://weco.io/p/3528).

--- 
## Roadmap

### Horizon one
- Finishing the Systematic interface plugin for Weco/Obsidian
- Discussing methodology specifics on Weco.io as a practice based community currency

### Horizon two
- DAO Codification w/Cosmos Groups Module and `authz` function (viable systems model structure)
- Describing general systematics as an AD4M Language
- Integrating Regen's data module as a perspective
- Integrating Regen's eco-credit module as a perspective

### Horizon three
- Anchoring Regenerating Sonoras pilot data on chain with the data module
- Issuing systematics as a semantic credit class and minting pilot eco-credits

---

## Teams as Viable System
- Purpose :: Interface :: WeCo.io
- Intelligence :: Community :: Regenerating Sonora
- Operations :: Logistics & Coordination ::  LunarPunk_Labs
- Coordination Task :: Product :: VISN_Labs
- Resourcing :: Backend integration :: Sovereign Nature Initiative

## DAO Roadmap
### Horizon one
- LunarPunk_Labs 
	- DAO Structure as a viable systems model
		- (-) Technology 
			- Purpose: Interface, Social Graph, Semantic web, Quality Assurance
			- Intelligence: Impact evaluators, Active Inference, Attestations
			- Operations: Devops, Facilitation
			- Coordination Task: Impact Certificates, Claims
			- Resourcing: Research and Development, Ledger Security, Credits
		- (=) Markets
			- Purpose: Advocacy, Partnerships, Compliance, 
			- Intelligence: Community facilitation
			- Operations: Sales, Marketing, PR, Logistics, Events, Asset Management, Investment, Strategy, Aquisition, Analytics 
			- Coordination Task: Communications
			- Resourcing: Fundraising, Economics, Legal, Administration, 
		- (+) Applied Science: Place based communities 
			- Purpose: Empirical understanding, Education
			- Intelligence: Field learning, Pilot projects, DataScience
			- Operations: Facilitated Onboarding
			- Coordination Task: Lab Learning, Design
			- Resourcing: Rational inferences, Decision Science
### Horizon two
- H3 University
	- Consortium Governance
### Horizon three
- Giordano Bruno Institute
	- Regenerative blue fund as Registry 2.0


## Proposed Budget and Compensation Structure

%%
Regen Foundation can fund this work through any combination of the following:
-   A REGEN token grant
-   A Community Staking DAO grant (500k locked REGEN tokens) to fund the establishment of a Tokenomics DAO
-   A token delegation (of REGEN, or potentially of ATOM and OSMO as well)

RND, Inc. can fund this work through a combination of:
-   Token grants with 1 year lock up of up to 200k REGEN
-   $25k USD cash payment
-   Token delegations
%%



## References / Bibliography
- [Regen Registry Guide](https://library.regen.network/v/regen-registry-program-guide/regen-registry-overview/structure)
- [LunarPunk Weco channel](https://weco.io/s/lunarpunklabs/posts)
- [Regen Request For Proposals](https://commonwealth.im/regen/discussion/7802-request-for-proposals-regen-tokenomics-upgrade)
- [Gaia BioHabitat Commons](https://docs.google.com/presentation/d/13xWKMRdfa1vJauJCn8SQq9fQqP9EEVJOowg78PU9hwM/edit#slide=id.g14d6de67000_0_617)
- [Blockscience propaganda](https://docs.google.com/presentation/d/1xvr_47iPlf1FTx7O2irqBGMCo-Z_7qdU/edit#slide=id.g89d5288067a441a_10)
- [Facets Journal](https://www.facetsjournal.com/doi/10.1139/facets-2020-0114)
- [Social–ecological hotspots mapping: A spatial approach for identifying coupled social–ecological space](https://www.sciencedirect.com/science/article/abs/pii/S0169204607002216)
- [Defining and measuring the social-ecological quality of urban greenspace: a semi-systematic review](https://link.springer.com/article/10.1007/s11252-015-0456-6)
- [Enhancing the Ostrom social-ecological system framework through formalization](https://www.ecologyandsociety.org/vol19/iss3/art51/)
- [Integrating sense of place into ecosystem restoration: a novel approach to achieve synergistic social-ecological impact](https://www.ecologyandsociety.org/vol23/iss4/art25/)
- [Weco: An ontological design framework](https://docs.google.com/document/d/1ZvIr9r9hl4E1RU4t885TyuXW0gCpt2Ad4ieYOT--a90/edit)
- [The healing-growth future of humanity: regenerative politics and crealectic care](http://uu.diva-portal.org/smash/get/diva2:1620901/FULLTEXT02.pdf)
- [Castela: The Citedel of Truth](https://docs.google.com/document/d/16FZnGeNaxPD32S_vvw5idHM0ULka_ObUpo1-c_x-LJU/edit) - generating conversation graphs
- [Holonic Medium](https://docs.google.com/document/d/1hc7UMHlvaFpwaDPzcseTycUlHRIy1NlJpHfGQgB_c-I/edit#heading=h.nhvltdokqxbd)
- [Towards Ecological Economics](https://medium.com/regen-network/towards-ecological-economics-de0c035e622e)
- [The emporers new markov blanket](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/emperors-new-markov-blankets/715C589A73DDF861DCF8997271DE0B8C)
- [Active Inferrence ontology](https://zenodo.org/record/6320575#.Y-FQ0xPP2Ev)
- [Generalised Impact Evaluators](https://research.protocol.ai/publications/generalized-impact-evaluators/ngwhitepaper2.pdf)
- PurplePill.vision

## Quality Control


